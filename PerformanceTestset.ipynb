{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "import click\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from addict import Dict\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchnet.meter import MovingAverageValueMeter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from libs.datasets import get_dataset\n",
    "from libs.models import *\n",
    "from libs.utils import DenseCRF, PolynomialLR, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(dirs):\n",
    "    if not os.path.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "\n",
    "def get_device(cuda):\n",
    "    cuda = cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    if cuda:\n",
    "        print(\"Device:\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(\"    {}:\".format(i), torch.cuda.get_device_name(i))\n",
    "    else:\n",
    "        print(\"Device: CPU\")\n",
    "    return device\n",
    "\n",
    "\n",
    "def get_params(model, key):\n",
    "    # For Dilated FCN\n",
    "    if key == \"1x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"layer\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    for p in m[1].parameters():\n",
    "                        yield p\n",
    "    # For conv weight in the ASPP module\n",
    "    if key == \"10x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"aspp\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    yield m[1].weight\n",
    "    # For conv bias in the ASPP module\n",
    "    if key == \"20x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"aspp\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    yield m[1].bias\n",
    "\n",
    "\n",
    "def resize_labels(labels, size):\n",
    "    \"\"\"\n",
    "    Downsample labels for 0.5x and 0.75x logits by nearest interpolation.\n",
    "    Other nearest methods result in misaligned labels.\n",
    "    -> F.interpolate(labels, shape, mode='nearest')\n",
    "    -> cv2.resize(labels, shape, interpolation=cv2.INTER_NEAREST)\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        label = label.float().numpy()\n",
    "        label = Image.fromarray(label).resize(size, resample=Image.NEAREST)\n",
    "        new_labels.append(np.asarray(label))\n",
    "    new_labels = torch.LongTensor(new_labels)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"data/models/S2DS/deeplabv2_resnet101_msc/train/checkpoint_final.pth\"\n",
    "config_path = \"configs/S2DS.yaml\"\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:\n",
      "    0: Tesla V100-PCIE-16GB\n",
      "    1: Tesla V100-PCIE-16GB\n",
      "Dataset: S2DS\n",
      "    # data: 157\n",
      "    Split: val\n",
      "    Root: S2DSdevkit/part2\n"
     ]
    }
   ],
   "source": [
    "with open(config_path, 'r') as file:\n",
    "    CONFIG = Dict(yaml.load(file, Loader=yaml.FullLoader))\n",
    "device = get_device(cuda)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Dataset\n",
    "dataset = get_dataset(CONFIG.DATASET.NAME)(\n",
    "    root=CONFIG.DATASET.ROOT,\n",
    "    split=CONFIG.DATASET.SPLIT.VAL,\n",
    "    ignore_label=CONFIG.DATASET.IGNORE_LABEL,\n",
    "    mean_bgr=(CONFIG.IMAGE.MEAN.B, CONFIG.IMAGE.MEAN.G, CONFIG.IMAGE.MEAN.R),\n",
    "    augment=False,\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=CONFIG.SOLVER.BATCH_SIZE.TEST,\n",
    "    num_workers=CONFIG.DATALOADER.NUM_WORKERS,\n",
    "    shuffle=False,\n",
    ")\n",
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Model\\nmodel = eval(CONFIG.MODEL.NAME)(n_classes=CONFIG.DATASET.N_CLASSES)\\nstate_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\\nmodel.load_state_dict(state_dict)\\nmodel = nn.DataParallel(model)\\nmodel.eval()\\nmodel.to(device)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Model\n",
    "model = eval(CONFIG.MODEL.NAME)(n_classes=CONFIG.DATASET.N_CLASSES)\n",
    "state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state_dict)\n",
    "model = nn.DataParallel(model)\n",
    "model.eval()\n",
    "model.to(device)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('IMG_6272',)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_id, image, label = next(loader_iter)\n",
    "image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(image))\n",
    "print(type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10) \n",
    "from libs.visualization import show_pair\n",
    "show_pair(image_id, image, label, (CONFIG.IMAGE.MEAN.B, CONFIG.IMAGE.MEAN.G, CONFIG.IMAGE.MEAN.R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
